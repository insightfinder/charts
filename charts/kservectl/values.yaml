replicaCount: 1

image:
  repository: docker.io/insightfinderinc/kservectl
  pullPolicy: Always
  tag: "latest"

imagePullSecrets:
  - name: regcred

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  automount: true
  annotations: {}
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}
podLabels: {}
podSecurityContext: {}
securityContext: {}

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  className: "nginx"
  annotations:
    # nginx.ingress.kubernetes.io/auth-type: basic
    # Make sure to create this secret in the namespace beforehand
    nginx.ingress.kubernetes.io/auth-secret: kservectl-auth
    # The user name by default is user. You can change it to whatever you want.
    nginx.ingress.kubernetes.io/auth-realm: "Authentication Required - user"
  hosts:
    - host: gateway-gke-stg.insightfinder.com
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls:
    - secretName: ingress-tls
      hosts:
        - gateway-gke-stg.insightfinder.com

resources:
  requests:
    cpu: "100m"
    memory: "256Mi"
  limits:
    cpu: "500m"
    memory: "512Mi"

livenessProbe:
  httpGet:
    path: /docs
    port: http
readinessProbe:
  httpGet:
    path: /docs
    port: http

nodeSelector: {}
tolerations: []
affinity: {}

models:
  qwen2p5-7b-instruct:
    model_id: Qwen/Qwen2.5-7B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  qwen2p5-coder-3b:
    model_id: Qwen/Qwen2.5-Coder-3B
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-t4-16gb
    resources:
      requests:
        cpu: 2
        memory: 14Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 14Gi
        nvidia.com/gpu: 1

  qwen2p5-coder-7b-instruct:
    model_id: Qwen/Qwen2.5-Coder-7B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  deepseek-coder-7b-instruct-v1p5:
    model_id: deepseek-ai/deepseek-coder-7b-instruct-v1.5
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  deepseek-r1-distill-qwen-1p5b:
    model_id: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-t4-16gb
    resources:
      requests:
        cpu: 2
        memory: 14Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 14Gi
        nvidia.com/gpu: 1

  deepseek-r1-distill-qwen-7b:
    model_id: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  deepseek-r1-distill-llama-8b:
    model_id: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  mistral-7b-instruct-v0p3:
    model_id: mistralai/Mistral-7B-Instruct-v0.3
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  mistral-7b-v0p3:
    model_id: mistralai/Mistral-7B-v0.3
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  llama-v3p1-8b-instruct:
    model_id: meta-llama/Llama-3.1-8B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  llama-v3-8b-instruct:
    model_id: meta-llama/Meta-Llama-3-8B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  llama-v3p2-3b-instruct:
    model_id: meta-llama/Llama-3.2-3B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: 0
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  tinyllama:
    model_id: TinyLlama/TinyLlama-1.1B-Chat-v1.0
    backend: vllm
    saved_on_pvc: true
    min_replicas: 1
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: k8s.amazonaws.com/accelerator
                  operator: In
                  values:
                    - nvidia-t4-16gb
            - matchExpressions:
                - key: cloud.google.com/gke-accelerator
                  operator: In
                  values:
                    - nvidia-l4
    resources:
      requests:
        cpu: 1
        memory: 10Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 1
        memory: 10Gi
        nvidia.com/gpu: 1

  smollm2:
    model_id: HuggingFaceTB/SmolLM2-135M-Instruct
    backend: huggingface
    saved_on_pvc: false
    min_replicas: 1
    resources:
      requests:
        cpu: 1
        memory: 2Gi
      limits:
        cpu: 1
        memory: 2Gi
