models:
  qwen2p5-7b-instruct:
    model_id: Qwen/Qwen2.5-7B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "qwen2p5-7b-instruct" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  qwen2p5-coder-3b:
    model_id: Qwen/Qwen2.5-Coder-3B
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "qwen2p5-coder-3b" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-t4-16gb
    resources:
      requests:
        cpu: 2
        memory: 14Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 14Gi
        nvidia.com/gpu: 1

  qwen2p5-coder-7b-instruct:
    model_id: Qwen/Qwen2.5-Coder-7B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "qwen2p5-coder-7b-instruct" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  deepseek-coder-7b-instruct-v1p5:
    model_id: deepseek-ai/deepseek-coder-7b-instruct-v1.5
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "deepseek-coder-7b-instruct-v1p5" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  deepseek-r1-distill-qwen-1p5b:
    model_id: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "deepseek-r1-distill-qwen-1p5b" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-t4-16gb
    resources:
      requests:
        cpu: 2
        memory: 14Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 14Gi
        nvidia.com/gpu: 1

  deepseek-r1-distill-qwen-7b:
    model_id: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "deepseek-r1-distill-qwen-7b" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  deepseek-r1-distill-llama-8b:
    model_id: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "deepseek-r1-distill-llama-8b" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  mistral-7b-instruct-v0p3:
    model_id: mistralai/Mistral-7B-Instruct-v0.3
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "mistral-7b-instruct-v0p3" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  mistral-7b-v0p3:
    model_id: mistralai/Mistral-7B-v0.3
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "mistral-7b-v0p3" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  llama-v3p1-8b-instruct:
    model_id: meta-llama/Llama-3.1-8B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "llama-v3p1-8b-instruct" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  llama-v3-8b-instruct:
    model_id: meta-llama/Meta-Llama-3-8B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "llama-v3-8b-instruct" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  llama-v3p2-3b-instruct:
    model_id: meta-llama/Llama-3.2-3B-Instruct
    backend: vllm
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "llama-v3p2-3b-instruct" "min_replicas" | default 0 }}
    node_selector:
      k8s.amazonaws.com/accelerator: nvidia-l40s-48gb
    resources:
      requests:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 2
        memory: 28Gi
        nvidia.com/gpu: 1

  tinyllama:
    model_id: TinyLlama/TinyLlama-1.1B-Chat-v1.0
    backend: vllm
    saved_on_pvc: true
    min_replicas: 1
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: k8s.amazonaws.com/accelerator
                  operator: In
                  values:
                    - nvidia-t4-16gb
            - matchExpressions:
                - key: cloud.google.com/gke-accelerator
                  operator: In
                  values:
                    - nvidia-l4
    resources:
      requests:
        cpu: 1
        memory: 10Gi
        nvidia.com/gpu: 1
      limits:
        cpu: 1
        memory: 10Gi
        nvidia.com/gpu: 1

  smollm2:
    model_id: HuggingFaceTB/SmolLM2-135M-Instruct
    backend: huggingface
    saved_on_pvc: true
    min_replicas: {{ index $.Values.models "smollm2" "min_replicas" | default 0 }}
    resources:
      requests:
        cpu: 1
        memory: 2Gi
      limits:
        cpu: 1
        memory: 2Gi
